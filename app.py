import streamlit as st
import os
import tempfile
import time

from langchain_community.chat_models import ChatOllama
from langchain_community.embeddings import OllamaEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AI Analyst (Dark)",
    page_icon="ğŸŒ™",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# 2. [ë””ìì¸] CSS (ì˜ë¦¼ ë°©ì§€ ë° ì¤‘ì•™ ì •ë ¬ ë°¸ëŸ°ìŠ¤)
st.markdown("""
<style>
    /* 1. ì•± ë°°ê²½ ë° í°íŠ¸ ì„¤ì • */
    .stApp {
        background-color: #0E1117;
        color: #FAFAFA;
    }

    /* 2. ë©”ì¸ ì»¨í…Œì´ë„ˆ ì—¬ë°± ì¡°ì • (ì˜ë¦¼ ë°©ì§€ í•µì‹¬) */
    .block-container {
        padding-top: 3rem !important; /* ìœ„ìª½ ì—¬ë°±ì„ ë„‰ë„‰íˆ ì£¼ì–´ ì˜ë¦¼ ë°©ì§€ */
        padding-bottom: 2rem !important;
        padding-left: 2rem !important;
        padding-right: 2rem !important;
        max-width: 100% !important;
    }

    /* 3. ì±„íŒ…ì°½ ë†’ì´ ìë™ ê³„ì‚° (í™”ë©´ ê½‰ ì±„ìš°ê¸°) */
    /* 100vh(ì „ì²´í™”ë©´) - 170px(ìƒë‹¨ ì—¬ë°± + ì…ë ¥ì°½ ë†’ì´ + í•˜ë‹¨ ì—¬ë°±) */
    [data-testid="stVerticalBlockBorderWrapper"] {
        height: calc(100vh - 170px) !important;
        background-color: #161920; 
        border: 1px solid #303030;
        border-radius: 12px;
        overflow-y: auto; 
        display: flex;
        flex-direction: column;
    }

    /* ìŠ¤í¬ë¡¤ë°” ë””ìì¸ */
    ::-webkit-scrollbar { width: 8px; }
    ::-webkit-scrollbar-thumb { background: #444; border-radius: 4px; }
    ::-webkit-scrollbar-track { background: #161920; }

    /* 4. íŒŒì¼ ì—…ë¡œë” ë””ìì¸ */
    .stFileUploader {
        background-color: transparent !important;
        border: 1px dashed #555;
        border-radius: 8px;
        padding: 5px;
    }
    .stFileUploader div { color: #ccc !important; }
    .stFileUploader small { display: none; }

    /* 5. ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton button {
        width: 100%;
        background-color: #262730;
        color: white;
        border: 1px solid #444;
        border-radius: 8px;
        height: 3em;
    }
    .stButton button:hover { background-color: #363945; }

    /* 6. ì…ë ¥ì°½ ìŠ¤íƒ€ì¼ */
    .stChatInputContainer { background-color: #0E1117 !important; padding-bottom: 1rem !important; }
    .stChatInput input { color: white !important; }

    /* 7. í—¤ë” ìˆ¨ê¸°ê¸° (ê³µê°„ í™•ë³´) */
    header {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)


# 3. ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_llm():
    return ChatOllama(model="qwen3-vl:8b", num_ctx=8096, temperature=0.1)


@st.cache_resource
def load_embedding_model():
    return OllamaEmbeddings(model='qwen3-embedding:latest')


try:
    llm = load_llm()
    embeddings = load_embedding_model()
except Exception:
    st.error("âš ï¸ Ollama ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨.")
    st.stop()

# 4. ì„¸ì…˜ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None
if "last_uploaded_file" not in st.session_state:
    st.session_state.last_uploaded_file = None
if "process_complete" not in st.session_state:
    st.session_state.process_complete = False

# ==========================================
# [ë ˆì´ì•„ì›ƒ] 3:7 ë¶„í• 
# ==========================================
col_left, col_right = st.columns([3, 7], gap="medium")

# ---------------------------------------------------------
# [LEFT] ì„¤ì • íŒ¨ë„
# ---------------------------------------------------------
with col_left:
    st.markdown("### ğŸŒ™ AI Analyst")

    # 1. RAG ëª¨ë“œ í† ê¸€
    use_rag = st.toggle("ğŸ“„ ë¬¸ì„œ ë¶„ì„ ëª¨ë“œ (RAG)", value=True)

    # 2. íƒ­ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬
    tab1, tab2 = st.tabs(["ğŸ“„ RAG ì„¤ì •", "ğŸ’¬ ì¼ë°˜ ì„¤ì •"])

    with tab1:
        rag_prompt = st.text_area(
            "RAG í”„ë¡¬í”„íŠ¸",
            value="ë‹¹ì‹ ì€ ëƒ‰ì² í•œ ë°ì´í„° ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë¬¸ì„œ ë‚´ìš©ì— ê¸°ë°˜í•˜ì—¬ ì‚¬ì‹¤ë§Œ ë‹µë³€í•˜ì„¸ìš”.",
            height=120,
            key="rag_prompt_input"
        )
        if use_rag and not st.session_state.vectorstore:
            st.warning("ğŸ‘‡ ì•„ë˜ì—ì„œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    with tab2:
        general_prompt = st.text_area(
            "ì¼ë°˜ ëŒ€í™” í”„ë¡¬í”„íŠ¸",
            value="ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ AI ë¹„ì„œì…ë‹ˆë‹¤. ììœ ë¡­ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.",
            height=120,
            key="general_prompt_input"
        )

    st.markdown("---")

    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("PDF ì—…ë¡œë“œ", type="pdf", label_visibility="collapsed")

    status_area = st.empty()

    if uploaded_file:
        if st.session_state.last_uploaded_file != uploaded_file.name:
            status_area.info("â³ ë¶„ì„ ì¤‘...")
            try:
                with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                    tmp_file.write(uploaded_file.getvalue())
                    tmp_file_path = tmp_file.name

                #pdf ì½ê¸°
                loader = PyPDFLoader(tmp_file_path)
                docs = loader.load()


                # ë¬¸ë§¥ ë‚˜ëˆ„ê¸°
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
                split_docs = text_splitter.split_documents(docs)


                #ë°±í„° ì €ì¥
                vectorstore = Chroma.from_documents(split_docs, embeddings)

                st.session_state.vectorstore = vectorstore
                st.session_state.last_uploaded_file = uploaded_file.name
                st.session_state.process_complete = True

                os.unlink(tmp_file_path)
                status_area.success("âœ… ì™„ë£Œ")
                time.sleep(1)
                status_area.empty()

            except Exception as e:
                status_area.error(f"Error: {e}")
        else:
            if st.session_state.process_complete:
                status_area.caption(f"ğŸ“‘ {uploaded_file.name}")

        st.markdown("<div style='height:10px'></div>", unsafe_allow_html=True)
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.rerun()

# ---------------------------------------------------------
# [RIGHT] ì±„íŒ…ì°½ (ìƒí•˜ì¢Œìš° ê½‰ ì°¸)
# ---------------------------------------------------------
with col_right:
    # ë†’ì´ ê³„ì‚° ë¡œì§ ìˆ˜ì •ìœ¼ë¡œ ì¸í•´ ìƒí•˜ê°€ ê½‰ ì°¨ê²Œ ë Œë”ë§ë¨
    chat_container = st.container(height=500, border=True)

    with chat_container:
        if not st.session_state.messages:
            msg = "ë¬¸ì„œë¥¼ ë¶„ì„í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤." if use_rag else "ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”."
            st.markdown(
                f"""
                <div style='display: flex; flex-direction: column; align-items: center; justify-content: center; height: 100%; color: #666;'>
                    <h3>ğŸŒ‘ {msg}</h3>
                </div>
                """,
                unsafe_allow_html=True
            )

        # HTML ë§í’ì„  ë Œë”ë§
        for message in st.session_state.messages:
            role = message["role"]
            content = message["content"]

            if role == "user":
                st.markdown(f"""
                <div style='display: flex; justify-content: flex-end; margin-bottom: 10px;'>
                    <div style='background-color: #2b5c8a; color: white; padding: 10px 15px; border-radius: 15px 15px 0 15px; max-width: 75%; box-shadow: 0 2px 5px rgba(0,0,0,0.2);'>
                        {content}
                    </div>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style='display: flex; justify-content: flex-start; margin-bottom: 10px;'>
                    <div style='background-color: #333333; color: #e0e0e0; padding: 10px 15px; border-radius: 15px 15px 15px 0; max-width: 75%; border: 1px solid #444;'>
                        {content}
                    </div>
                </div>
                """, unsafe_allow_html=True)

    # ì…ë ¥ì°½
    input_text = "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ğŸ“„ RAG)" if (use_rag and st.session_state.vectorstore) else "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ğŸ’¬ ì¼ë°˜)"

    if prompt := st.chat_input(input_text):
        st.session_state.messages.append({"role": "user", "content": prompt})

        with chat_container:
            st.markdown(f"""
            <div style='display: flex; justify-content: flex-end; margin-bottom: 10px;'>
                <div style='background-color: #2b5c8a; color: white; padding: 10px 15px; border-radius: 15px 15px 0 15px; max-width: 75%; box-shadow: 0 2px 5px rgba(0,0,0,0.2);'>
                    {prompt}
                </div>
            </div>
            """, unsafe_allow_html=True)

        # í”„ë¡¬í”„íŠ¸ ì„ íƒ ë¡œì§
        if use_rag and st.session_state.vectorstore:
            retrieved_docs = st.session_state.vectorstore.similarity_search(prompt, k=3)
            context_text = "\n".join([doc.page_content for doc in retrieved_docs])
            final_prompt = f"[ì§€ì‹œì‚¬í•­]\n{rag_prompt}\n\n[ë¬¸ì„œë‚´ìš©]\n{context_text}\n\n[ì§ˆë¬¸]\n{prompt}"
        else:
            final_prompt = f"[ì§€ì‹œì‚¬í•­]\n{general_prompt}\n\n[ì§ˆë¬¸]\n{prompt}"

        # AI ë‹µë³€ ìƒì„±
        with chat_container:
            message_placeholder = st.empty()
            full_response = ""

            try:
                for chunk in llm.stream(final_prompt):
                    full_response += chunk.content
                    message_placeholder.markdown(f"""
                    <div style='display: flex; justify-content: flex-start; margin-bottom: 10px;'>
                        <div style='background-color: #333333; color: #e0e0e0; padding: 10px 15px; border-radius: 15px 15px 15px 0; max-width: 75%; border: 1px solid #444;'>
                            {full_response}â–Œ
                        </div>
                    </div>
                    """, unsafe_allow_html=True)

                message_placeholder.markdown(f"""
                <div style='display: flex; justify-content: flex-start; margin-bottom: 10px;'>
                    <div style='background-color: #333333; color: #e0e0e0; padding: 10px 15px; border-radius: 15px 15px 15px 0; max-width: 75%; border: 1px solid #444;'>
                        {full_response}
                    </div>
                </div>
                """, unsafe_allow_html=True)

                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"Error: {e}")